## 从数据存取上来看
现代计算机由于 CPU 和内存之间存在 Cache，而 Cache 的数据存取速度远高于内存，因此，需要 CPU 每次访存的时候，能在 Cache 中命中。这里最经典的例子就是二维数组的按列访问和按行访问
```
// 按行访问
for(int i = 0; i < n; i ++) {
	for(int j = 0; j < n; j ++) {
		read(nums[i][j]);
	}
}
// 按列访问
for(int i = 0; i < n; i ++) {
	for(int j = 0; j < n; j ++) {
		read(nums[j][i]);
	}
}
```
根据局部性原理，CPU 在读取内存的时候，不是读一个拿一个，而是会将内存连续的一部分都放入 Cache 中，以便预测访问，只要在一次传输承受范围内，拿一个数据和拿一批数据速度是一致的，但是如果命中Cache 了，那收益是很高的。
```
// 内存中二维数组的存储方式
a[0][0], a[0][1], a[0][2], a[0][3]...
a[1][0], a[1][1], a[1][2], a[1][3]...
...
```
当 CPU 要获取 `a[0][0]` 时，会将 `a[0][0]`后面内存地址连续的一部分元素一起放入 Cache。这样我们按行访问的时候，大大提高了 Cache 命中率。
### 为什么不按照列拿入 cache 呢？
内存地址不连续，CPU 还得计算下一列的内存地址，与 Cache 设计背道而驰
## 从指令存取上来看
CPU 中有一个很关键的概念叫分支预测，让我们关注下面的这段代码，看看应该先执行操作一还是操作二
```
int array[N];
for(int i = 0; i < N; i ++) {
	array[i] = rand() % 100;
}

// 操作一
for(int i = 0; i < N; i ++) {
	if(array[i] < 50) {
		array[i] = 0;
	}
}
// 操作二
sort(array, array + N);
```
当 CPU 执行到上述代码的 if 的位置，因为CPU 处理指令也是要将指令读到缓存和指令寄存器中的，所以这里如果能预测 if 的走向，提前将对应的指令取到寄存器中，拿就可以大大减少指令存取的时间。
所以，上面先操作一时， if 由于数组中的数是无规律随机的，这样会大大减少 CPU 分支预测的准确性。而先执行排序，再进行操作一，这样会提高分支预测的准确性。
```
int p = 100;
int main() {
	if(p == 0) {
		cout << "hello" << endl
	}
	cout << "nihao" << endl
	return 0;
}
```
对于这段代码，执行的时候，实际上 CPU 会多次将 `cout << "hello" << endl` 这段指令取入指令寄存器，如果上述代码执行一百次，可能后面就不会存入寄存器了，因为 CPU 会认为预测失败率太高，转向另一个分支。
## 多线程角度
L1 和 L2 Cache 是每个 CPU 核心独享的哦。所以最好让线程绑定在一个核心上运行，这样减少了切换核心，Cache 命中率下降的可能性。